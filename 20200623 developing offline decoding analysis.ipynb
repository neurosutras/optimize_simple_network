{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_simple_network_replay import *\n",
    "baks_alpha = 4.7725100028345535\n",
    "baks_beta = 0.41969058927343522\n",
    "baks_pad_dur = 3000.  # ms\n",
    "baks_wrap_around = True\n",
    "context.update(locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronmil/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# run_data_file_path = 'data/20200610_144659_simple_network_J_8_exported_output.hdf5'\n",
    "# run_data_file_path = 'data/20200618_192138_simple_network_J_exported_output.hdf5'\n",
    "# run_data_file_path = 'data/20200619_163719_simple_network_J_exported_output.hdf5'\n",
    "# run_data_file_path = 'data/20200623_144723_simple_network_J_0_exported_output.hdf5'\n",
    "run_data_file_path = 'data/20200623_163137_simple_network_J_1_exported_output.hdf5'\n",
    "with h5py.File(run_data_file_path) as f:\n",
    "    trial_keys = [key for key in f if key != 'shared_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_run_trial_data_from_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-93e6ccf4b085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mrun_binned_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_run_firing_rates_matrix_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_gid_dict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             get_run_trial_data_from_file(run_data_file_path, trial_key, context.baks_alpha, context.baks_beta, \n\u001b[0m\u001b[1;32m      8\u001b[0m                                          context.baks_pad_dur, context.baks_wrap_around)\n\u001b[1;32m      9\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_run_trial_data_from_file' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "run_firing_rates_matrix_dict_list = []\n",
    "first = True\n",
    "for trial_key in trial_keys[:1]:\n",
    "    if first:\n",
    "        run_binned_t, this_run_firing_rates_matrix_dict, sorted_gid_dict = \\\n",
    "            get_run_trial_data_from_file(run_data_file_path, trial_key, context.baks_alpha, context.baks_beta, \n",
    "                                         context.baks_pad_dur, context.baks_wrap_around)\n",
    "        first = False \n",
    "    else:\n",
    "        _, this_run_firing_rates_matrix_dict, _ = \\\n",
    "            get_run_trial_data_from_file(run_data_file_path, trial_key)\n",
    "    run_firing_rates_matrix_dict_list.append(this_run_firing_rates_matrix_dict)\n",
    "\n",
    "print('Processing run data for %i trials took %.1f s' % (len(trial_keys), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_trial_run_firing_rates_matrix_dict = dict()\n",
    "trial_pop_sum_run_firing_rates_list_dict = defaultdict(list)\n",
    "mean_trial_pop_sum_run_firing_rates_dict = dict()\n",
    "sem_trial_pop_sum_run_firing_rates_dict = dict()\n",
    "first = run_firing_rates_matrix_dict_list[0]\n",
    "num_trials = len(run_firing_rates_matrix_dict_list)\n",
    "for pop_name in first:\n",
    "    trial_run_firing_rates_matrix_list = []\n",
    "    for i in range(num_trials):\n",
    "        this_trial_run_firing_rates_matrix = run_firing_rates_matrix_dict_list[i][pop_name]\n",
    "        trial_run_firing_rates_matrix_list.append(this_trial_run_firing_rates_matrix)\n",
    "        trial_pop_sum_run_firing_rates_list_dict[pop_name].append(np.sum(this_trial_run_firing_rates_matrix, axis=0))\n",
    "    mean_trial_run_firing_rates_matrix_dict[pop_name] = np.mean(trial_run_firing_rates_matrix_list, axis=0)\n",
    "    mean_trial_pop_sum_run_firing_rates_dict[pop_name] = np.mean(trial_pop_sum_run_firing_rates_list_dict[pop_name], axis=0)\n",
    "    sem_trial_pop_sum_run_firing_rates_dict[pop_name] = \\\n",
    "        np.std(trial_pop_sum_run_firing_rates_list_dict[pop_name], axis=0) / np.sqrt(num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8., 8.))\n",
    "for i, pop_name in enumerate(mean_trial_run_firing_rates_matrix_dict):\n",
    "    axes.flat[i].imshow(mean_trial_run_firing_rates_matrix_dict[pop_name], \n",
    "                   extent=(run_binned_t[0], run_binned_t[-1], 0, len(sorted_gid_dict[pop_name])), aspect='auto')\n",
    "    axes.flat[i].set_title(pop_name)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2)\n",
    "for i, pop_name in enumerate(trial_pop_sum_run_firing_rates_list_dict):\n",
    "    for j in range(num_trials):\n",
    "        axes.flat[i].plot(run_binned_t, trial_pop_sum_run_firing_rates_list_dict[pop_name][j], alpha=0.25)\n",
    "    axes.flat[i].plot(run_binned_t, mean_trial_pop_sum_run_firing_rates_dict[pop_name], c='r')\n",
    "    axes.flat[i].fill_between(run_binned_t, mean_trial_pop_sum_run_firing_rates_dict[pop_name] - \n",
    "                              sem_trial_pop_sum_run_firing_rates_dict[pop_name], \n",
    "                              mean_trial_pop_sum_run_firing_rates_dict[pop_name] + \n",
    "                              sem_trial_pop_sum_run_firing_rates_dict[pop_name], color='r', alpha=0.25)\n",
    "    axes.flat[i].set_ylim((0., axes.flat[i].get_ylim()[1]*1.1))\n",
    "    axes.flat[i].set_title(pop_name)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2)\n",
    "for i, pop_name in enumerate(full_pop_mean_rate_from_binned_spike_count_dict_list[0]):\n",
    "    all_trials = []\n",
    "    for j in range(num_trials):\n",
    "        this_pop_mean_rate_from_binned_spike_count = np.interp(run_binned_t, run_full_binned_t_list[j],\n",
    "                                                              full_pop_mean_rate_from_binned_spike_count_dict_list[j][pop_name])\n",
    "        axes.flat[i].plot(run_full_binned_t_list[j], full_pop_mean_rate_from_binned_spike_count_dict_list[j][pop_name], \n",
    "                          alpha=0.25)\n",
    "        all_trials.append(this_pop_mean_rate_from_binned_spike_count)\n",
    "    axes.flat[i].plot(run_binned_t, np.mean(all_trials, axis=0), c='k')\n",
    "    axes.flat[i].set_title(pop_name)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_t in run_full_binned_t_list:\n",
    "    print(run_t[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_name = 'E'\n",
    "run_full_spike_times_dict_list = []\n",
    "run_buffered_binned_spike_count_list = []\n",
    "run_buffered_firing_rates_list = []\n",
    "run_full_binned_t_list = []\n",
    "run_buffered_binned_t_list = []\n",
    "run_tuning_peak_locs_list = []\n",
    "run_data_group_key = 'simple_network_exported_data'\n",
    "for run_data_key in trial_keys:\n",
    "    with h5py.File(run_data_file_path, 'r') as f:\n",
    "        group = get_h5py_group(f, ['shared_context'])\n",
    "        run_buffered_binned_t = group['buffered_binned_t'][:]\n",
    "        run_binned_dt = run_buffered_binned_t[1] - run_buffered_binned_t[0]\n",
    "        run_buffered_binned_t_list.append(run_buffered_binned_t)\n",
    "        if 'tuning_peak_locs' in group and len(group['tuning_peak_locs']) > 0:\n",
    "            subgroup = group['tuning_peak_locs']\n",
    "            run_tuning_peak_locs = dict()\n",
    "            for target_gid, peak_loc in zip(subgroup[pop_name]['target_gids'], subgroup[pop_name]['peak_locs']):\n",
    "                run_tuning_peak_locs[target_gid] = peak_loc\n",
    "        run_tuning_peak_locs_list.append(run_tuning_peak_locs)\n",
    "        group = get_h5py_group(f, [run_data_key, run_data_group_key])\n",
    "        run_full_binned_t = group['full_binned_t'][:]\n",
    "        run_full_binned_t_list.append(run_full_binned_t)\n",
    "        run_full_spike_times_dict = dict()\n",
    "        subgroup = group['full_spike_times']\n",
    "        for gid_key in subgroup[pop_name]:\n",
    "            run_full_spike_times_dict[int(gid_key)] = subgroup[pop_name][gid_key][:]\n",
    "        run_full_spike_times_dict_list.append(run_full_spike_times_dict)\n",
    "        run_buffered_binned_spike_count_dict = get_binned_spike_count_dict({pop_name: run_full_spike_times_dict}, run_buffered_binned_t)\n",
    "        run_buffered_binned_spike_count_list.append(run_buffered_binned_spike_count_dict[pop_name])\n",
    "        run_inferred_binned_t, run_buffered_firing_rates_dict = \\\n",
    "            infer_firing_rates_from_spike_count(run_buffered_binned_spike_count_dict, input_t=run_buffered_binned_t, \n",
    "                                                output_range=(run_buffered_binned_t[0], run_buffered_binned_t[-1]), \n",
    "                                                align_to_t=0., window_dur=20., step_dur=20.)\n",
    "        run_buffered_firing_rates_list.append(run_buffered_firing_rates_dict[pop_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 0\n",
    "gid = next(iter(run_buffered_binned_spike_count_list[trial]))\n",
    "plt.figure()\n",
    "for trial in range(len(trial_keys)):\n",
    "    plt.plot(run_buffered_binned_t_list[trial], run_buffered_binned_spike_count_list[trial][gid], alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pop_sum_binned_spike_count_list = []\n",
    "for trial in range(len(trial_keys)):\n",
    "    pop_sum_binned_spike_count = np.sum(list(run_buffered_firing_rates_list[trial].values()), axis=0)\n",
    "    pop_sum_binned_spike_count_list.append(pop_sum_binned_spike_count)\n",
    "    plt.plot(run_inferred_binned_t, pop_sum_binned_spike_count, alpha=0.25)\n",
    "plt.plot(run_inferred_binned_t, np.mean(pop_sum_binned_spike_count_list, axis=0), c='k')\n",
    "plt.ylim((0., plt.ylim()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pop_sum_binned_spike_count_list = []\n",
    "for trial in range(len(trial_keys)):\n",
    "    pop_sum_binned_spike_count = np.sum(list(run_buffered_binned_spike_count_list[trial].values()), axis=0)\n",
    "    pop_sum_binned_spike_count_list.append(pop_sum_binned_spike_count)\n",
    "    plt.plot(run_buffered_binned_t_list[trial], pop_sum_binned_spike_count, alpha=0.25)\n",
    "plt.plot(run_buffered_binned_t_list[trial], np.mean(pop_sum_binned_spike_count_list, axis=0), c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 0\n",
    "gid = next(iter(run_buffered_binned_spike_count_list[trial]))\n",
    "plt.figure()\n",
    "pop_sum_binned_spike_count_list = []\n",
    "for trial in range(len(trial_keys)):\n",
    "    pop_sum_binned_spike_count = run_buffered_firing_rates_list[trial][gid]\n",
    "    pop_sum_binned_spike_count_list.append(pop_sum_binned_spike_count)\n",
    "    plt.plot(run_inferred_binned_t, pop_sum_binned_spike_count, alpha=0.25)\n",
    "plt.plot(run_inferred_binned_t, np.mean(pop_sum_binned_spike_count_list, axis=0), c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
